# ConfiguraÃ§Ã£o para Desenvolvimento - GLM-4.7

## ğŸ¯ Suas EspecificaÃ§Ãµes

Baseado no seu hardware:
- **CPU**: AMD Ryzen 5 5600X (6 cores, 12 threads) âœ…
- **GPU**: RTX 4060 (8GB VRAM) âœ…
- **RAM**: 32GB âœ…
- **Disco**: 174GB livres âœ…

## âœ… Status dos Scripts

**SIM, os scripts estÃ£o prontos para funcionar!** Eles foram ajustados especificamente para sua configuraÃ§Ã£o.

## ğŸ“¦ Modelo Recomendado para VocÃª

### **Q4_K_S** (Recomendado)

**Por quÃª?**
- âœ… **Tamanho**: 180GB (cabe no seu disco)
- âœ… **RAM**: Funciona com 32GB (mÃ­nimo recomendado: 48GB, mas funciona)
- âœ… **VRAM**: Otimizado para 8GB com offloading inteligente
- âœ… **Qualidade**: Boa qualidade para cÃ³digo (4-bit quantizado)
- âœ… **Performance**: Balanceada entre qualidade e velocidade

**ConfiguraÃ§Ã£o otimizada:**
- **GPU Layers**: 6 camadas na GPU (resto em CPU)
- **Contexto**: 4096 tokens (suficiente para arquivos de cÃ³digo)
- **Threads**: 6 threads CPU (aproveitando seus 12 threads)

## ğŸš€ Passo a Passo para ComeÃ§ar

### 1. Detectar e Configurar Hardware

```powershell
.\scripts\detect-hardware.ps1
```

Este script vai:
- Detectar sua RTX 4060 e configurar CUDA arch 8.9 automaticamente
- Detectar 32GB RAM e 8GB VRAM
- Gerar configuraÃ§Ã£o otimizada para desenvolvimento

### 2. Instalar DependÃªncias

```powershell
.\scripts\install.ps1
```

**Nota**: No Windows, o llama.cpp precisa ser compilado. OpÃ§Ãµes:
- **OpÃ§Ã£o A (Recomendada)**: Use WSL2 (Windows Subsystem for Linux)
- **OpÃ§Ã£o B**: Baixe build prÃ©-compilado de https://github.com/ggerganov/llama.cpp/releases
- **OpÃ§Ã£o C**: Compile com Visual Studio (mais complexo)

### 3. Baixar Modelo

```powershell
.\scripts\download-model.ps1 -Version Q4_K_S
```

**AtenÃ§Ã£o**: 
- O download Ã© de ~180GB
- Pode demorar vÃ¡rias horas dependendo da conexÃ£o
- Certifique-se de ter espaÃ§o suficiente

### 4. Executar para Desenvolvimento

```powershell
.\scripts\run-llamacpp.ps1 -ModelVersion Q4_K_S -CtxSize 4096 -Threads 6 -GpuLayers 6
```

Ou simplesmente (os parÃ¢metros serÃ£o detectados automaticamente):
```powershell
.\scripts\run-llamacpp.ps1
```

## âš™ï¸ ConfiguraÃ§Ãµes para Desenvolvimento

### Perfis de Uso

**GeraÃ§Ã£o de CÃ³digo (mais preciso):**
```powershell
.\scripts\run-llamacpp.ps1 -Prompt "Escreva uma funÃ§Ã£o Python que..." -CtxSize 4096
```
- Temperatura: 0.5-0.7 (mais determinÃ­stico)
- Contexto: 4096 tokens (suficiente para arquivos mÃ©dios)

**ExplicaÃ§Ã£o de CÃ³digo:**
```powershell
.\scripts\run-llamacpp.ps1 -Prompt "Explique este cÃ³digo: [cÃ³digo aqui]" -CtxSize 4096
```
- Temperatura: 0.7-0.8 (mais criativo)
- Contexto: 4096 tokens

**RevisÃ£o de CÃ³digo:**
```powershell
.\scripts\run-llamacpp.ps1 -Prompt "Revise este cÃ³digo e sugira melhorias: [cÃ³digo]" -CtxSize 4096
```
- Temperatura: 0.6 (balanceado)
- Contexto: 4096 tokens

## ğŸ”§ OtimizaÃ§Ãµes EspecÃ­ficas para Seu Hardware

### Aproveitando a RTX 4060 (8GB VRAM)

Os scripts estÃ£o configurados para:
1. **Offloading inteligente**: 6 camadas na GPU, resto em CPU
2. **Economia de VRAM**: Camadas MoE (experts) sÃ£o movidas para CPU automaticamente
3. **Contexto otimizado**: 4096 tokens (nÃ£o muito grande para nÃ£o estourar memÃ³ria)

### Aproveitando o Ryzen 5 5600X

- **6 threads CPU**: Aproveita metade dos 12 threads disponÃ­veis
- **Deixa recursos livres**: Para vocÃª continuar usando o PC normalmente

## âš ï¸ LimitaÃ§Ãµes e Expectativas

### Performance Esperada

Com sua configuraÃ§Ã£o:
- **Velocidade de geraÃ§Ã£o**: ~2-5 tokens/segundo (dependendo do offloading)
- **Uso de RAM**: ~20-25GB durante execuÃ§Ã£o
- **Uso de VRAM**: ~6-7GB (deixando ~1GB livre)
- **Uso de CPU**: ~50% (6 de 12 threads)

### Quando Funciona Melhor

âœ… **Ideal para:**
- GeraÃ§Ã£o de funÃ§Ãµes e classes
- ExplicaÃ§Ã£o de cÃ³digo
- RefatoraÃ§Ã£o de cÃ³digo
- SugestÃµes de melhorias
- Debugging assistido

âš ï¸ **Pode ser lento para:**
- Arquivos muito grandes (>4000 tokens)
- MÃºltiplas iteraÃ§Ãµes rÃ¡pidas
- Contexto muito extenso

## ğŸ†˜ SoluÃ§Ã£o de Problemas

### "Out of memory"
- Reduza contexto: `-CtxSize 2048`
- Reduza GPU layers: `-GpuLayers 4`
- Feche outros programas

### "Muito lento"
- Normal! Com 32GB RAM e 8GB VRAM, Ã© esperado
- Considere usar serviÃ§os em nuvem para tarefas muito pesadas
- Para desenvolvimento local, a velocidade Ã© aceitÃ¡vel

### "Modelo nÃ£o encontrado"
- Verifique se o download terminou: `ls models/`
- O arquivo deve ter ~180GB

## ğŸ’¡ Dicas para Desenvolvimento

1. **Use contexto pequeno**: Para cÃ³digo, 4096 tokens Ã© suficiente
2. **Temperatura baixa**: 0.5-0.7 para cÃ³digo mais preciso
3. **Prompt especÃ­fico**: Seja claro sobre o que vocÃª quer
4. **Iterativo**: FaÃ§a perguntas menores e especÃ­ficas

## ğŸ“Š ComparaÃ§Ã£o de Modelos para VocÃª

| Modelo | Tamanho | RAM | VRAM | Qualidade | Velocidade | Recomendado? |
|--------|---------|-----|------|-----------|------------|--------------|
| Q4_K_S | 180GB | 32GB | 8GB | â­â­â­â­ | â­â­â­ | âœ… **SIM** |
| Q4_K_M | 200GB | 64GB | 16GB | â­â­â­â­â­ | â­â­ | âŒ Muita RAM |
| Q5_K_M | 240GB | 80GB | 20GB | â­â­â­â­â­ | â­ | âŒ Muita RAM |
| UD-Q2_K_XL | 135GB | 128GB | 24GB | â­â­â­â­â­ | â­â­â­ | âŒ Muita RAM |

## ğŸ¯ ConclusÃ£o

**Para desenvolvimento/codificaÃ§Ã£o com seu hardware:**
- âœ… Use **Q4_K_S**
- âœ… Configure **6 GPU layers + offload CPU**
- âœ… Use **contexto de 4096 tokens**
- âœ… Temperatura **0.5-0.7** para cÃ³digo

Os scripts estÃ£o prontos e otimizados para sua mÃ¡quina! ğŸš€
